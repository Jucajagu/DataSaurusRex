@misc{Young1995,
   author = {I T Young and J J Gerbrands and L J Van Vliet},
   title = {Fundamentals of Image Processing},
   year = {1995},
}
@article{Sharma2018,
   abstract = {This paper presents an empirical analysis of theperformance of popular convolutional neural networks (CNNs) for identifying objects in real time video feeds. The most popular convolution neural networks for object detection and object category classification from images are Alex Nets, GoogLeNet, and ResNet50. A variety of image data sets are available to test the performance of different types of CNN's. The commonly found benchmark datasets for evaluating the performance of a convolutional neural network are anImageNet dataset, and CIFAR10, CIFAR100, and MNIST image data sets. This study focuses on analyzing the performance of three popular networks: Alex Net, GoogLeNet, and ResNet50. We have taken three most popular data sets ImageNet, CIFAR10, and CIFAR100 for our study, since, testing the performance of a network on a single data set does not reveal its true capability and limitations. It must be noted that videos are not used as a training dataset, they are used as testing datasets. Our analysis shows that GoogLeNet and ResNet50 are able to recognize objects with better precision compared to Alex Net. Moreover, theperformance of trained CNN's vary substantially across different categories of objects and we, therefore, will discuss the possible reasons for this.},
   author = {Neha Sharma and Vibhor Jain and Anju Mishra},
   doi = {10.1016/j.procs.2018.05.198},
   issn = {18770509},
   journal = {Procedia Computer Science},
   keywords = {CNN,Deep Learning,Neural network,Object classification,Object detection},
   month = {1},
   pages = {377-384},
   publisher = {Elsevier},
   title = {An Analysis Of Convolutional Neural Networks For Image Classification},
   volume = {132},
   url = {https://linkinghub.elsevier.com/retrieve/pii/S1877050918309335},
   year = {2018},
}
@article{Chen2021,
   abstract = {<p>Image classification has always been a hot research direction in the world, and the emergence of deep learning has promoted the development of this field. Convolutional neural networks (CNNs) have gradually become the mainstream algorithm for image classification since 2012, and the CNN architecture applied to other visual recognition tasks (such as object detection, object localization, and semantic segmentation) is generally derived from the network architecture in image classification. In the wake of these successes, CNN-based methods have emerged in remote sensing image scene classification and achieved advanced classification accuracy. In this review, which focuses on the application of CNNs to image classification tasks, we cover their development, from their predecessors up to recent state-of-the-art (SOAT) network architectures. Along the way, we analyze (1) the basic structure of artificial neural networks (ANNs) and the basic network layers of CNNs, (2) the classic predecessor network models, (3) the recent SOAT network algorithms, (4) comprehensive comparison of various image classification methods mentioned in this article. Finally, we have also summarized the main analysis and discussion in this article, as well as introduce some of the current trends.</p>},
   author = {Leiyu Chen and Shaobo Li and Qiang Bai and Jing Yang and Sanlong Jiang and Yanming Miao},
   doi = {10.3390/rs13224712},
   issn = {2072-4292},
   issue = {22},
   journal = {Remote Sensing},
   keywords = {convolutional neural networks,deep learning,image classification},
   month = {11},
   pages = {4712},
   publisher = {Multidisciplinary Digital Publishing Institute},
   title = {Review of Image Classification Algorithms Based on Convolutional Neural Networks},
   volume = {13},
   url = {https://www.mdpi.com/2072-4292/13/22/4712},
   year = {2021},
}
@inbook{Zeiler2014,
   abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets. © 2014 Springer International Publishing.},
   author = {Matthew D. Zeiler and Rob Fergus},
   doi = {10.1007/978-3-319-10590-1_53},
   isbn = {9783319105895},
   issn = {16113349},
   issue = {PART 1},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   pages = {818-833},
   publisher = {Springer Verlag},
   title = {Visualizing and Understanding Convolutional Networks},
   volume = {8689 LNCS},
   url = {http://link.springer.com/10.1007/978-3-319-10590-1_53},
   year = {2014},
}
@article{Dumoulin2016,
   abstract = {We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures. The guide clarifies the relationship between various properties (input shape, kernel shape, zero padding, strides and output shape) of convolutional, pooling and transposed convolutional layers, as well as the relationship between convolutional and transposed convolutional layers. Relationships are derived for various cases, and are illustrated in order to make them intuitive.},
   author = {Vincent Dumoulin and Francesco Visin},
   month = {3},
   title = {A guide to convolution arithmetic for deep learning},
   url = {http://arxiv.org/abs/1603.07285},
   year = {2016},
}
@article{Cireşan2011,
   abstract = {We present a fast, fully parameterizable GPU implementation of Convolutional Neural Network variants. Our feature extractors are neither carefully designed nor pre-wired, but rather learned in a supervised way. Our deep hierarchical architectures achieve the best published results on benchmarks for object classification (NORB, CIFAR10) and handwritten digit recognition (MNIST), with error rates of 2.53%, 19.51%, 0.35%, respectively. Deep nets trained by simple back-propagation perform better than more shallow ones. Learning is surprisingly rapid. NORB is completely trained within five epochs. Test error rates on MNIST drop to 2.42%, 0.97% and 0.48% after 1, 3 and 17 epochs, respectively.},
   author = {Dan C. Cireşan and Ueli Meier and Jonathan Masci and Luca M. Gambardella and Jürgen Schmidhuber},
   month = {2},
   title = {High-Performance Neural Networks for Visual Object Classification},
   url = {http://arxiv.org/abs/1102.0183},
   year = {2011},
}
